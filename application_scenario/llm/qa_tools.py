from langchain_ollama import ChatOllama
from langchain.tools import tool
from langgraph.prebuilt import create_react_agent
from langchain_core.messages import HumanMessage, SystemMessage
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# å…¨åŸŸ RAG åˆå§‹åŒ–
embedding_model = HuggingFaceEmbeddings(model_name="BAAI/bge-m3")
loader = DirectoryLoader(
    "docs",
    glob="**/*.md",
    loader_cls=lambda path: TextLoader(path, encoding="utf-8"),
    show_progress=True
)
docs = loader.load()
splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)
split_docs = splitter.split_documents(docs)
vector_db = FAISS.from_documents(split_docs, embedding_model)
retriever = vector_db.as_retriever()

@tool
def get_order_info(order_id: str) -> dict:
    """é€é API å–å¾—æŒ‡å®šè¨‚å–®çš„è³‡è¨Šï¼Œä¾‹å¦‚è¨‚å–®ç‹€æ…‹å’Œè¿½è¹¤è™Ÿã€‚"""
    print('order_id: ', order_id)
    return {"status": "shipped", "tracking": "ABC123"}

@tool
def get_inventory(product_id: str) -> dict:
    """æŸ¥è©¢æŒ‡å®šå•†å“çš„åº«å­˜æ•¸é‡å’Œå¯ç”¨æ€§ã€‚"""
    print('product_id: ', product_id)
    return {"stock": 50, "available": True}

@tool
def rag_retrieve(query: str) -> str:
    """å¾çŸ¥è­˜åº«æª¢ç´¢èˆ‡æŸ¥è©¢ç›¸é—œçš„è³‡è¨Šã€‚"""
    query_docs = retriever.get_relevant_documents(query)
    return "\n".join([doc.page_content for doc in query_docs])

# åˆå§‹åŒ– ChatOllama
llm = ChatOllama(
    model="llama3.1",  # æ”¹ç”¨æ”¯æ´å·¥å…·èª¿ç”¨çš„æ¨¡å‹
    base_url="http://localhost:11434"
)
tools = [get_order_info, get_inventory, rag_retrieve]  # åŠ å…¥ rag_retrieve
agent = create_react_agent(llm, tools)

system_message = SystemMessage(content="""ä½ æ˜¯é›»å•†å®¢æœï¼Œå›ç­”ç°¡æ½”ä¸”å°ˆæ¥­ã€‚
æ­¥é©Ÿ1: è§£æç”¨æˆ¶æŸ¥è©¢ï¼ˆè¨‚å–®ã€åº«å­˜ã€å…¶ä»–ï¼‰ã€‚
æ­¥é©Ÿ2: ä½¿ç”¨é©ç•¶å·¥å…·ï¼ˆget_order_infoã€get_inventoryã€rag_retrieveï¼‰ç²å–è³‡æ–™ã€‚
æ­¥é©Ÿ3: åˆæˆå‹å–„çš„è‡ªç„¶èªè¨€å›æ‡‰ã€‚""")

while True:
    question = input("ğŸ” å•é¡Œ / Question: ")
    if question.lower() in {"exit", "quit"}:
        break
    messages = [system_message, HumanMessage(content=question)]
    response = agent.invoke({"messages": messages})
    print("\nğŸ“£ å›ç­” / Answer:\n", response["messages"][-1].content)
    print("\n------------------------------------------------------------------------------------\n")